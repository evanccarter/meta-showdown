#the following will generate a list with condition informaiton (the simulated process), estimation
#performance (how well MA estimators and some other methods did) and sample information on the 
#meta-analytic samples generated (median N per study, power, etc.)

out = simSum(nMA = 1000,                      #collect data from 1000 MAs.
             k = 20,                          #each MA has 20 studies in it.
             QRP = 0, sel = 0, propB = 0,    #no p-hacking occurs (QRP=0), but 60% of studies
                                              #(propB=.6) will be influenced by publication 
                                              #selection bias so that they must have a positive 
                                              #and sig result (sel = 1).
             meanD = .5, sigma = 0,          #the average of the true effects for each study is
                                              #d = .5 (meanD = .5), the SD (sigma) is .2.
             cbdv = .5, maxN = 100,           #cbdv and maxN are only used with raw data generation
                                              #so these can be tucked away in future versions.
             minN = 10, meanN = 30, sdN = 25, #for study-level sample generation, the min of the 
                                              #truncated normal is 10 (minN = 10) and the mean is 30
                                              #(meanN = 30) while the SD is 25 (sdN = 25).
             multDV = 0,out = 0,mod = 0,      #the final 5 arguments are specific to p-hacking--see
             colLim = 0,add = 0)              #notes for dataMA()

#NOTE: Getting an error I don't understand... I don't get the error when I don't use any bias. 
#Warning messages:
#  1: In Gin(G(a, ...) + p * (G(b, ...) - G(a, ...)), ...) :
#  full precision may not have been achieved in 'pnt{final}'
#2: In Gin(G(a, ...) + p * (G(b, ...) - G(a, ...)), ...) :
#  full precision may not have been achieved in 'pnt{final}'

#NOTE: the answers I'm getting don't make sense... With no heterogeneity and no bias and a meanD
#of .5 I'm seeing RE mean error/bias as -.34. That's crazy. I suspect something is wrong with 
#data generation. 
